{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glue setup\n",
    "%idle_timeout 2880\n",
    "%glue_version 3.0\n",
    "%worker_type G.1X\n",
    "%number_of_workers 5\n",
    "\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "  \n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import boto3\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import io\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import s3fs\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "# Define AWS boto3 clients\n",
    "athena_client = boto3.client('athena')\n",
    "glue_client = boto3.client('glue', region_name='us-east-1')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Define s3 and Athena paths\n",
    "athena_db = 'iasworld'\n",
    "\n",
    "s3_bucket = 'ccao-data-warehouse-us-east-1'\n",
    "s3_prefix = 'reporting/ratio_stats/'\n",
    "s3_output = 's3://'+ s3_bucket + '/' + s3_prefix\n",
    "s3_ratio_stats = 's3://'+ s3_bucket + '/' + s3_prefix + 'ratio_stats.parquet'\n",
    "\n",
    "\n",
    "# Functions to help with Athena queries ----\n",
    "def poll_status(athena_client, execution_id):\n",
    "    \"\"\" Checks the status of the a query using an incoming execution id and returns\n",
    "    a 'pass' string value when the status is either SUCCEEDED, FAILED or CANCELLED. \"\"\"\n",
    "\n",
    "    result = athena_client.get_query_execution(QueryExecutionId=execution_id)\n",
    "    state  = result['QueryExecution']['Status']['State']\n",
    "\n",
    "    if state == 'SUCCEEDED':\n",
    "        return 'pass'\n",
    "    if state == 'FAILED':\n",
    "        return 'pass'\n",
    "    if state == 'CANCELLED':\n",
    "        return 'pass'\n",
    "    else:\n",
    "        return 'not pass'\n",
    "\n",
    "def poll_result(athena_client, execution_id):\n",
    "    \"\"\" Gets the query result using an incoming execution id. This function is ran after the\n",
    "    poll_status function and only if we are sure that the query was fully executed. \"\"\"\n",
    "\n",
    "    result = athena_client.get_query_execution(QueryExecutionId=execution_id)\n",
    "\n",
    "    return result\n",
    "\n",
    "def run_query_get_result(\n",
    "  athena_client,\n",
    "  s3_bucket,\n",
    "  query,\n",
    "  database,\n",
    "  s3_output,\n",
    "  s3_prefix):\n",
    "    \"\"\" Runs an incoming query and returns the output as an s3 file like object.\n",
    "    \"\"\"\n",
    "\n",
    "    response = athena_client.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={\n",
    "            'Database': database\n",
    "        },\n",
    "        ResultConfiguration={\n",
    "            'OutputLocation': s3_output,\n",
    "    })\n",
    "\n",
    "    QueryExecutionId = response.get('QueryExecutionId')\n",
    "\n",
    "    # Wait until query is executed\n",
    "    while poll_status(athena_client, QueryExecutionId) != 'pass':\n",
    "        time.sleep(2)\n",
    "        pass\n",
    "\n",
    "    result = poll_result(athena_client, QueryExecutionId)\n",
    "\n",
    "    r_file_object = None\n",
    "\n",
    "    # Only return file like object when the query succeeded\n",
    "    if result['QueryExecution']['Status']['State'] == 'SUCCEEDED':\n",
    "        print(\"Query SUCCEEDED: {}\".format(QueryExecutionId))\n",
    "\n",
    "        s3_key = s3_prefix + QueryExecutionId + '.csv'\n",
    "\n",
    "        r_file_object = boto3.resource('s3').Object(s3_bucket, s3_key)\n",
    "\n",
    "    return r_file_object\n",
    "\n",
    "\n",
    "# Athena query ----\n",
    "SQL_QUERY = \"\"\"\n",
    "-- THIS SCRIPT NEEDS TO BE UPDATED WITH FINAL MODEL RUN IDs EACH YEAR\n",
    "\n",
    "-- Valuation class from pardat\n",
    "WITH classes AS (\n",
    "\n",
    "    SELECT\n",
    "        parid,\n",
    "        taxyr,\n",
    "        class,\n",
    "        CASE WHEN class in ('299', '399') THEN 'CONDO'\n",
    "            when class in ('211', '212') THEN 'MF'\n",
    "            when class in ('202', '203', '204', '205', '206', '207', '208', '209', '210', '234', '278', '295') THEN 'SF'\n",
    "            ELSE NULL END AS property_group\n",
    "    FROM iasworld.pardat\n",
    "\n",
    "    ),\n",
    "-- Townships from legdat since pardat has some errors we can't accept for public reporting\n",
    "townships AS (\n",
    "\n",
    "    SELECT\n",
    "        parid,\n",
    "        taxyr,\n",
    "        substr(TAXDIST, 1, 2) AS township_code,\n",
    "        triad_code AS triad\n",
    "    FROM iasworld.legdat\n",
    "\n",
    "    LEFT JOIN spatial.township\n",
    "        ON substr(TAXDIST, 1, 2) = township_code\n",
    "\n",
    "),\n",
    "-- Final model values\n",
    "model_values AS (\n",
    "\n",
    "    SELECT\n",
    "        meta_pin AS parid,\n",
    "        CAST(CAST(meta_year AS INT) + 1 AS VARCHAR) AS year,\n",
    "        'model' AS assessment_stage,\n",
    "        pred_pin_final_fmv_round AS total\n",
    "    FROM model.assessment_pin\n",
    "\n",
    "    LEFT JOIN classes\n",
    "        ON assessment_pin.meta_pin = classes.parid AND assessment_pin.meta_year = classes.taxyr\n",
    "    LEFT JOIN townships\n",
    "        ON assessment_pin.meta_pin = townships.parid AND assessment_pin.meta_year = townships.taxyr\n",
    "\n",
    "    WHERE run_id IN ('2022-04-26-beautiful-dan', '2022-04-27-keen-gabe')\n",
    "        AND property_group IS NOT NULL\n",
    "\n",
    "),\n",
    "-- Values by assessment stages available in iasWorld (not model)\n",
    "iasworld_values AS (\n",
    "\n",
    "    SELECT\n",
    "        asmt_all.parid,\n",
    "        asmt_all.taxyr as year,\n",
    "        CASE\n",
    "            WHEN procname = 'CCAOVALUE' THEN 'mailed'\n",
    "            WHEN procname = 'CCAOFINAL' THEN 'assessor certified'\n",
    "            WHEN procname = 'BORVALUE'  THEN 'bor certified'\n",
    "            ELSE NULL END AS assessment_stage,\n",
    "        max(\n",
    "            CASE\n",
    "                WHEN asmt_all.taxyr < '2020' THEN ovrvalasm3\n",
    "                WHEN asmt_all.taxyr >= '2020' THEN valasm3\n",
    "                ELSE NULL END\n",
    "            ) * 10 AS total\n",
    "    FROM iasworld.asmt_all\n",
    "\n",
    "    WHERE (valclass IS null OR asmt_all.taxyr < '2020')\n",
    "      AND procname IN ('CCAOVALUE', 'CCAOFINAL', 'BORVALUE')\n",
    "      AND asmt_all.taxyr >= '2021'\n",
    "\n",
    "    GROUP BY\n",
    "        asmt_all.parid,\n",
    "        asmt_all.taxyr,\n",
    "        procname,\n",
    "        CASE\n",
    "            WHEN procname = 'CCAOVALUE' THEN 'mailed'\n",
    "            WHEN procname = 'CCAOFINAL' THEN 'assessor certified'\n",
    "            WHEN procname = 'BORVALUE'  THEN 'bor certified'\n",
    "            ELSE NULL END\n",
    "),\n",
    "-- Stack iasWorld and model values\n",
    "all_values AS (\n",
    "    SELECT * FROM model_values\n",
    "    UNION\n",
    "    SELECT * FROM iasworld_values\n",
    ")\n",
    "-- Sales, filtered to exclude outliers and mutlisales\n",
    "    SELECT\n",
    "        vps.pin,\n",
    "        av.year,\n",
    "        vps.year AS sale_year,\n",
    "        property_group,\n",
    "        assessment_stage,\n",
    "        triad,\n",
    "        townships.township_code,\n",
    "        av.total AS fmv,\n",
    "        sale_price,\n",
    "        av.total / sale_price AS ratio\n",
    "    FROM default.vw_pin_sale vps\n",
    "\n",
    "    LEFT JOIN classes\n",
    "        ON vps.pin = classes.parid AND vps.year = classes.taxyr\n",
    "    LEFT JOIN townships\n",
    "        ON vps.pin = townships.parid AND vps.year = townships.taxyr\n",
    "    -- Join sales so that values for a given year can be compared to a complete set of sales from the previous year\n",
    "    INNER JOIN all_values av ON vps.pin = av.parid\n",
    "        AND CAST(vps.year AS INT) = CAST(av.year AS INT) - 1\n",
    "    -- Grab parking spaces and join them to aggregate stats for removal\n",
    "    LEFT JOIN (\n",
    "      SELECT * FROM default.vw_pin_condo_char WHERE is_parking_space = TRUE\n",
    "      ) ps ON av.parid = ps.pin AND av.year = ps.year\n",
    "\n",
    "    WHERE is_multisale = FALSE\n",
    "        AND property_group IS NOT NULL\n",
    "        AND ps.pin IS NULL;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Run run_query_get_result to get file like object ----\n",
    "r_file_object = run_query_get_result(\n",
    "    athena_client,\n",
    "    s3_bucket,\n",
    "    SQL_QUERY,\n",
    "    athena_db,\n",
    "    s3_output,\n",
    "    s3_prefix\n",
    ")\n",
    "\n",
    "# Retrieve s3 location of Athena query result and retrieve it\n",
    "target = 's3://'+ s3_bucket + '/' + r_file_object.key\n",
    "\n",
    "pull = pd.read_csv(target)\n",
    "pull = pull[pull.ratio > 0 & pull.ratio.notnull()]\n",
    "\n",
    "# Delete all query results for this job from s3 bucket\n",
    "response = s3_client.list_objects_v2(Bucket = s3_bucket, Prefix = s3_prefix)\n",
    "\n",
    "for object in response['Contents']:\n",
    "    if re.search(\"csv\", object['Key']):\n",
    "        print('Deleting', object['Key'])\n",
    "        s3_client.delete_object(Bucket = s3_bucket, Key = object['Key'])\n",
    "\n",
    "\n",
    "# COD, PRD, PRB functions ----\n",
    "def cod(ratio):\n",
    "\n",
    "    n = ratio.size\n",
    "    median_ratio = ratio.median()\n",
    "    cod = 100 / median_ratio * (sum(abs(ratio - median_ratio)) / n)\n",
    "\n",
    "    return cod\n",
    "\n",
    "def prd(fmv, sale_price):\n",
    "\n",
    "    ratio = fmv / sale_price\n",
    "    prd = ratio.mean() / np.average(a = ratio, weights = sale_price)\n",
    "\n",
    "    return prd\n",
    "\n",
    "def prb(fmv, sale_price):\n",
    "\n",
    "    ratio = fmv / sale_price\n",
    "    median_ratio = ratio.median()\n",
    "\n",
    "    lhs = (ratio - median_ratio) /median_ratio\n",
    "    rhs = np.log(((fmv / median_ratio) + sale_price) / 2) / np.log(2)\n",
    "\n",
    "    lhs = np.array(lhs)\n",
    "    rhs = np.array(rhs)\n",
    "\n",
    "    return sm.OLS(lhs, rhs).fit()\n",
    "\n",
    "# Functions to determine whether assessment fairness criteria has been met\n",
    "cod_met = lambda x: 5 <= x <= 15\n",
    "\n",
    "prd_met = lambda x: 0.98 <= x <= 1.03\n",
    "\n",
    "prb_met = lambda x: -0.05 <= x <= 0.05\n",
    "\n",
    "# General boostrapping function\n",
    "def boot_ci(fun, *args, nboot = 100, alpha = 0.05):\n",
    "\n",
    "    num_args = len(args)\n",
    "    args = pd.DataFrame(args).T\n",
    "    n = len(args)\n",
    "\n",
    "    ests = []\n",
    "\n",
    "    for i in list(range(1, nboot)):\n",
    "        sample = args.sample(n = n, replace = True)\n",
    "        if fun.__name__ == 'cod' or num_args == 1:\n",
    "            ests.append(fun(sample.iloc[:, 0]))\n",
    "        elif fun.__name__ in ['prd', 'prb']:\n",
    "            ests.append(fun(sample.iloc[:, 0], sample.iloc[:, 1]))\n",
    "\n",
    "    ests = pd.Series(ests)\n",
    "\n",
    "    ci = [ests.quantile(alpha / 2), ests.quantile(1 - alpha / 2)]\n",
    "\n",
    "    ci = ', '.join([str(element) for element in ci])\n",
    "\n",
    "    return ci\n",
    "\n",
    "# Formula specific bootstrapping functions\n",
    "def cod_boot(ratio, nboot = 100, alpha = 0.05):\n",
    "\n",
    "    return boot_ci(cod, ratio, nboot = nboot, alpha = alpha)\n",
    "\n",
    "def prd_boot(fmv, sale_price, nboot = 100, alpha = 0.05):\n",
    "\n",
    "    return boot_ci(prd, fmv, sale_price, nboot = nboot, alpha = alpha)\n",
    "\n",
    "def median_boot(ratio, nboot = 100, alpha = 0.05):\n",
    "\n",
    "    return boot_ci(np.median, ratio, nboot = nboot, alpha = alpha)\n",
    "\n",
    "# Fairness metrics functions that comply with CCAO's SOPs\n",
    "def ccao_cod(ratio):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    # Remove top and bottom 5% of ratios as per CCAO Data Department SOPs\n",
    "    no_outliers = ratio[ratio.between(ratio.quantile(0.05), ratio.quantile(0.95), inclusive = \"neither\")]\n",
    "\n",
    "    cod_n = no_outliers.size\n",
    "\n",
    "    if cod_n >= 20:\n",
    "\n",
    "        cod_val = cod(no_outliers)\n",
    "        cod_ci = boot_ci(cod, no_outliers, nboot = 1000)\n",
    "        met = cod_met(cod_val)\n",
    "\n",
    "        out = [cod_val, cod_ci, met, cod_n]\n",
    "\n",
    "    else:\n",
    "\n",
    "        out = [None, None, None, cod_n]\n",
    "\n",
    "    return out\n",
    "\n",
    "def ccao_prd(fmv, sale_price):\n",
    "\n",
    "    ratio = fmv / sale_price\n",
    "\n",
    "    # Remove top and bottom 5% of ratios as per CCAO Data Department SOPs\n",
    "    no_outliers = ratio.between(ratio.quantile(0.05), ratio.quantile(0.95), inclusive = \"neither\")\n",
    "\n",
    "    fmv_no_outliers = fmv[no_outliers == True]\n",
    "    sale_price_no_outliers = sale_price[no_outliers == True]\n",
    "\n",
    "    prd_n = sum(no_outliers)\n",
    "\n",
    "    if prd_n >= 20:\n",
    "\n",
    "        prd_val = prd(fmv_no_outliers, sale_price_no_outliers)\n",
    "        prd_ci = prd_boot(fmv_no_outliers, sale_price_no_outliers, nboot = 1000)\n",
    "        met = prd_met(prd_val)\n",
    "\n",
    "        out = [prd_val, prd_ci, met, prd_n]\n",
    "\n",
    "    else:\n",
    "\n",
    "        out = [None, None, None, prd_n]\n",
    "\n",
    "    return out\n",
    "\n",
    "def ccao_prb(fmv, sale_price):\n",
    "\n",
    "    ratio = fmv / sale_price\n",
    "\n",
    "    # Remove top and bottom 5% of ratios as per CCAO Data Department SOPs\n",
    "    no_outliers = ratio.between(ratio.quantile(0.05), ratio.quantile(0.95), inclusive = \"neither\")\n",
    "\n",
    "    fmv_no_outliers = fmv[no_outliers == True]\n",
    "    sale_price_no_outliers = sale_price[no_outliers == True]\n",
    "\n",
    "    prb_n = sum(no_outliers)\n",
    "\n",
    "    if prb_n >= 20:\n",
    "\n",
    "        prb_model = prb(fmv_no_outliers, sale_price_no_outliers)\n",
    "        prb_val = float(prb_model.params)\n",
    "        prb_ci = ', '.join(\n",
    "            [str(element) for element in prb_model.conf_int(alpha = 0.05)[0].tolist()]\n",
    "            )\n",
    "        met = prb_met(prb_val)\n",
    "\n",
    "        out = [prb_val, prb_ci, met, prb_n]\n",
    "\n",
    "    else:\n",
    "\n",
    "        out = [None, None, None, prb_n]\n",
    "\n",
    "    return out\n",
    "\n",
    "def ccao_median(x):\n",
    "\n",
    "    # Remove top and bottom 5% of ratios as per CCAO Data Department SOPs\n",
    "    no_outliers = x.between(x.quantile(0.05), x.quantile(0.95), inclusive = \"neither\")\n",
    "\n",
    "    x_no_outliers = x[no_outliers == True]\n",
    "\n",
    "    median_n = sum(no_outliers)\n",
    "\n",
    "    median_val = np.median(x_no_outliers)\n",
    "    median_ci = median_boot(x, nboot = 1000)\n",
    "\n",
    "    out = [median_val, median_ci, median_n]\n",
    "\n",
    "    return(out)\n",
    "\n",
    "# Sales chasing functions\n",
    "def detect_chasing_cdf(ratio, bounds = [0.98, 1.02], cdf_gap = 0.03):\n",
    "    # CDF gap method for detecting sales chasing.\n",
    "\n",
    "    # Sort the ratios\n",
    "    sorted_ratio = ratio.sort_values()\n",
    "\n",
    "    # Calculate the CDF of the sorted ratios and extract percentile ranking\n",
    "    cdf = ECDF(sorted_ratio)(sorted_ratio)\n",
    "\n",
    "    # Calculate the difference between each value and the next value, the largest\n",
    "    # difference will be the CDF gap\n",
    "    diffs = np.diff(cdf)\n",
    "\n",
    "    # Check if the largest difference is greater than the threshold and make sure\n",
    "    # it's within the specified boundaries\n",
    "    diff_loc = sorted_ratio.iloc[np.argmax(diffs)]\n",
    "    out = (max(diffs) > cdf_gap) & ((diff_loc > bounds[0]) & (diff_loc < bounds[1]))\n",
    "\n",
    "    return(out)\n",
    "\n",
    "def detect_chasing_dist(ratio, bounds = [0.98, 1.02]):\n",
    "    # Distribution comparison method for detecting sales chasing.\n",
    "\n",
    "    # Return the percentage of x within the specified range\n",
    "    def pct_in_range(x, min, max):\n",
    "        out = np.mean(((x >= min) & (x <= max)))\n",
    "        return out\n",
    "\n",
    "    # Calculate the ideal normal distribution using observed values from input\n",
    "    ideal_dist = np.random.normal(\n",
    "        loc = np.mean(ratio),\n",
    "        scale = np.std(ratio),\n",
    "        size = 10000\n",
    "        )\n",
    "\n",
    "    # Determine what percentage of the data would be within the specified bounds\n",
    "    # in the ideal distribution\n",
    "    pct_ideal = pct_in_range(ideal_dist, bounds[0], bounds[1])\n",
    "\n",
    "    # Determine what percentage of the data is actually within the bounds\n",
    "    pct_actual = pct_in_range(ratio, bounds[0], bounds[1])\n",
    "\n",
    "    return pct_actual > pct_ideal\n",
    "\n",
    "def detect_chasing(ratio, method = 'both'):\n",
    "\n",
    "    # Remove top and bottom 5% of ratios as per CCAO Data Department SOPs\n",
    "    no_outliers = ratio.between(ratio.quantile(0.05), ratio.quantile(0.95), inclusive = \"neither\")\n",
    "\n",
    "    if len(no_outliers) < 30:\n",
    "        warnings.warn(\n",
    "            \"\"\"Sales chasing detection can be misleading when applied to small samples (N < 30).\n",
    "            Increase N or use a different statistical test.\"\"\"\n",
    "            )\n",
    "\n",
    "        out = None\n",
    "\n",
    "    else:\n",
    "        out = {\n",
    "            'cdf': detect_chasing_cdf(no_outliers),\n",
    "            'dist': detect_chasing_dist(no_outliers),\n",
    "            'both': (detect_chasing_cdf(no_outliers) & detect_chasing_dist(no_outliers))\n",
    "        }.get(method)\n",
    "\n",
    "    return out\n",
    "\n",
    "def report_summarise(df, geography_id, geography_type):\n",
    "    # Aggregates data and calculates summary statistics for given groupings\n",
    "\n",
    "    group_cols = ['year', 'triad', 'geography_type', 'property_group', 'assessment_stage', 'geography_id', 'sale_year']\n",
    "\n",
    "    df['geography_id'] = pull[geography_id]\n",
    "    df['geography_type'] = geography_type\n",
    "\n",
    "    # Remove groups with less than three observations\n",
    "    df['n'] = df.groupby(group_cols)['ratio'].transform('count')\n",
    "    df = df[df['n'] > 2]\n",
    "    df = df.groupby(group_cols).apply(\n",
    "        lambda x: pd.Series({\n",
    "            'sale_n':np.size(x['triad']),\n",
    "            'ratio':ccao_median(x['ratio']),\n",
    "            'cod':ccao_cod(ratio = x['ratio']),\n",
    "            'prd':ccao_prd(fmv = x['fmv'], sale_price = x['sale_price']),\n",
    "            'prb':ccao_prb(fmv = x['fmv'], sale_price = x['sale_price']),\n",
    "            'detect_chasing':detect_chasing(ratio = x['ratio']),\n",
    "            'within_20_pct':sum(abs(1 - x['ratio']) <= .20),\n",
    "            'within_10_pct':sum(abs(1 - x['ratio']) <= .10),\n",
    "            'within_05_pct':sum(abs(1 - x['ratio']) <= .05),\n",
    "            })\n",
    "        )\n",
    "    df[['median_ratio', 'median_ratio_ci', 'median_ratio_n']] = pd.DataFrame(df.ratio.tolist(), index = df.index)\n",
    "    df[['cod', 'cod_ci', 'cod_met', 'cod_n']] = pd.DataFrame(df.cod.tolist(), index = df.index)\n",
    "    df[['prd', 'prd_ci', 'prd_met', 'prd_n']] = pd.DataFrame(df.prd.tolist(), index = df.index)\n",
    "    df[['prb', 'prb_ci', 'prb_met', 'prb_n']] = pd.DataFrame(df.prb.tolist(), index = df.index)\n",
    "    df['ratio_met'] = abs(1 - df['median_ratio']) <= .05\n",
    "    df['vertical_equity_met'] = (df.prd_met | df.prb_met)\n",
    "\n",
    "    # Arrange output columns\n",
    "    df = df[[\n",
    "        'sale_n',\n",
    "        'median_ratio',\n",
    "        'median_ratio_ci',\n",
    "        'cod',\n",
    "        'cod_ci',\n",
    "        'cod_n',\n",
    "        'prd',\n",
    "        'prd_ci',\n",
    "        'prd_n',\n",
    "        'prb',\n",
    "        'prb_ci',\n",
    "        'prb_n',\n",
    "        'detect_chasing',\n",
    "        'ratio_met',\n",
    "        'cod_met',\n",
    "        'prd_met',\n",
    "        'prb_met',\n",
    "        'vertical_equity_met',\n",
    "        'within_20_pct',\n",
    "        'within_10_pct',\n",
    "        'within_05_pct'\n",
    "]].reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Append and write output to s3 bucket\n",
    "pd.concat([\n",
    "    report_summarise(pull, 'triad', 'Tri'),\n",
    "    report_summarise(pull, 'township_code', 'Town')\n",
    "    ]).to_parquet(\n",
    "        s3_ratio_stats\n",
    "        )\n",
    "\n",
    "# Trigger reporting glue crawler\n",
    "glue_client.start_crawler(Name='ccao-data-warehouse-reporting-crawler')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
