#!/usr/bin/env python3
#
# Generates an Excel workbook of dbt test failures that can be shared with
# other teams for review and correction.
#
# This script assumes that it is being run in sequence after a call to
# `dbt test --store-failures`, since it depends on two files created by
# that operation (target/run_results.json and target/manifest.json).
# It also requires Python dependencies be installed from
# format_dbt_test_failures_requirements.txt.
#
# Accepts three optional positional arguments:
#
#   1. The local path to a run_results.json file generated by a test run
#     * If not present, defaults to './target/run_results.json'
#   2. The local path to a manifest.json file with the compiled dbt DAG
#     * If not present, defaults to './target/manifest.json'
#   3. The output filepath to which the workbook should be written
#     * If not present, defaults to './qc_test_failures_<date>.xlsx'
#
# Expects one optional environment variable to be set:
#
#  1.AWS_ATHENA_S3_STAGING_DIR: Location in S3 where Athena query results
#    should be written. If missing, defaults to the
#    ccao-athena-results-us-east-1 bucket
#
# Each sheet in the output workbook represents a category of test, e.g.
# "valid_range" or "not_null"; each row in a sheet represents a row in a
# database that failed a test, with enough metadata that a reader can
# figure out what conditions caused the test to fail and investigate the
# root cause.
#
# Example usage:
#
#   AWS_ATHENA_S3_STAGING_DIR=s3://foo-bar-baz/ \
#       python3 format_dbt_test_failures.py \
#       ./target/run_results.json \
#       ./target/manifest.json \
#       ./qc_test_failures.xlsx

import dataclasses
import datetime
import json
import os
import sys
import typing

import openpyxl
import openpyxl.styles
import openpyxl.utils
import pyathena
import pyathena.cursor
from openpyxl.worksheet.worksheet import Worksheet

# Tests without a config.meta.category property will be grouped in
# this default category
DEFAULT_TEST_CATEGORY = "miscellaneous"
# Prefix for the URL location of a test in the dbt docs
DOCS_URL_PREFIX = "https://ccao-data.github.io/data-architecture/#!/test"
# The S3 bucket where Athena query results are stored
AWS_ATHENA_S3_STAGING_DIR = os.getenv(
    "AWS_ATHENA_S3_STAGING_DIR", "s3://ccao-athena-results-us-east-1/"
)
# Field names that are used in the output workbook
SOURCE_TABLE_FIELD = "source_table"
DESCRIPTION_FIELD = "description"
TEST_NAME_FIELD = "test_name"
DOCS_URL_FIELD = "docs_url"
TAXYR_FIELD = "taxyr"
PARID_FIELD = "parid"
CARD_FIELD = "card"
TOWNSHIP_FIELD = "township_code"
WHO_FIELD = "who"
WEN_FIELD = "wen"


@dataclasses.dataclass
class FailedTestGroup:
    """Class to store query results for a group of failed dbt tests and provide
    convenience methods for formatting those results for output to a report."""

    # Names of fields that are used for debugging
    _debugging_field_names = [TEST_NAME_FIELD, DOCS_URL_FIELD]
    # List that defines the order that diagnostic fields should appear in
    # the output workbook
    _diagnostic_field_order = [
        SOURCE_TABLE_FIELD,
        DESCRIPTION_FIELD,
        TEST_NAME_FIELD,
        DOCS_URL_FIELD,
        TAXYR_FIELD,
        PARID_FIELD,
        CARD_FIELD,
        TOWNSHIP_FIELD,
        WHO_FIELD,
        WEN_FIELD,
    ]

    def __init__(self) -> None:
        self._rows: typing.List[typing.Dict] = []

    def update(self, new_rows: typing.List[typing.Dict]) -> None:
        """Add a list of new_rows to the rows of failing tests tracked by
        this group. The new_rows list should be formatted like the rows
        returned by a csv.DictReader or a DictCursor, i.e. a list of
        dicts mapping `{column_name: row_value}`."""
        self._rows = [*self._rows, *new_rows]

    @property
    def fieldnames(self) -> typing.List[str]:
        """Get a list of fieldnames that encapsulates all of the fieldnames
        for all of the rows of failing tests tracked by this group."""
        fieldnames = []
        for row in self._rows:
            for column in row.keys():
                if column not in fieldnames:
                    fieldnames.append(column)

        # Reorder the list so that diagnostic fields are presented in the
        # correct order
        for new_idx, field in enumerate(self._diagnostic_field_order):
            try:
                old_idx = fieldnames.index(field)
            except ValueError:
                # The field must not be contained in this sheet, so skip it
                continue

            if new_idx == old_idx:
                continue

            # Move the element in the list from the old index to the new one
            fieldnames.insert(new_idx, fieldnames.pop(old_idx))

        return fieldnames

    @property
    def rows(self) -> typing.List[typing.List]:
        """Format the rows of failing tests tracked by this group, with
        fieldname data excluded. The combination of this property and the
        `fieldnames` property can be used to write to a csv.Writer or
        to an openpyxl.Workbook sheet for the tests tracked by this group."""
        fieldnames = self.fieldnames
        return [
            [row.get(fieldname) for fieldname in fieldnames]
            for row in self._rows
        ]

    @property
    def debugging_field_indexes(self) -> typing.List[str]:
        """Get a list of field indexes (e.g. ["A", "B"]) for fields that
        are used for debugging."""
        fieldnames = self.fieldnames
        return [
            # openpyxl is 1-indexed while the index() method is 0-indexed
            openpyxl.utils.get_column_letter(fieldnames.index(field) + 1)
            for field in self._debugging_field_names
        ]


# Type representing a mapping of sheet names to the tests contained therein
FailedTestsByCategory = typing.Dict[str, FailedTestGroup]


def main() -> None:
    """Entrypoint to this script. Parses dbt test failures and writes a
    workbook of test failures to the output path."""
    try:
        run_results_filepath = sys.argv[1]
    except IndexError:
        run_results_filepath = os.path.join("target", "run_results.json")

    try:
        manifest_filepath = sys.argv[2]
    except IndexError:
        manifest_filepath = os.path.join("target", "manifest.json")

    try:
        output_filepath = sys.argv[3]
    except IndexError:
        date_today = datetime.datetime.today().strftime("%Y-%m-%d")
        output_filepath = f"qc_test_failures_{date_today}.xlsx"

    with open(run_results_filepath) as run_results_fobj:
        run_results = json.load(run_results_fobj)

    with open(manifest_filepath) as manifest_fobj:
        manifest = json.load(manifest_fobj)

    failed_tests_by_category = get_failed_tests_by_category(
        run_results, manifest
    )
    if not failed_tests_by_category:
        raise ValueError(f"{run_results_filepath} contains no failed rows")

    workbook = openpyxl.Workbook()
    for sheet_name, failed_test_group in failed_tests_by_category.items():
        add_sheet_to_workbook(workbook, sheet_name, failed_test_group)
    workbook.save(output_filepath)


def get_failed_tests_by_category(
    run_results: typing.Dict, manifest: typing.Dict
) -> FailedTestsByCategory:
    """Given two artifacts from a `dbt test --store-failures` call (a
    run_results.json file dict and a manifest.json file dict), generates a dict
    where each key is a name of a sheet and each associated value is
    a list of failed tests for that sheet."""
    conn = pyathena.connect(
        s3_staging_dir=AWS_ATHENA_S3_STAGING_DIR,
        region_name="us-east-1",
        cursor_class=pyathena.cursor.DictCursor,
    )
    cursor = conn.cursor()

    failed_tests_by_category: FailedTestsByCategory = {}

    for result in run_results["results"]:
        if result["status"] == "fail":
            unique_id = result["unique_id"]
            # Link to the test's page in the dbt docs, for debugging
            test_docs_url = f"{DOCS_URL_PREFIX}/{unique_id}"

            node = manifest["nodes"].get(unique_id)
            if node is None:
                raise ValueError(
                    f"Missing dbt manifest node with id {unique_id}"
                )

            test_name = node["name"]
            meta = node.get("meta", {})
            category = get_category_from_node(node)
            tablename = get_tablename_from_node(node)
            test_description = meta.get("description")

            # Get the fully-qualified name of the table that stores failures
            # for this test so that we can query it
            test_results_relation_name = node.get("relation_name")
            if test_results_relation_name is None:
                raise ValueError(
                    f"Missing relation_name attribute for test {test_name}. "
                    "Did you run `dbt test` with the --store-failures flag?"
                )

            print(f"Querying failed rows from {test_results_relation_name}")
            cursor.execute(f"select * from {test_results_relation_name}")
            query_results = cursor.fetchall()
            if len(query_results) == 0:
                raise ValueError(
                    f"Test {test_name} has status 'fail' but no failing rows "
                    "in Athena"
                )

            # Add custom fields to query results that we don't expect to be
            # included in the response
            failed_tests = [
                {
                    TEST_NAME_FIELD: test_name,
                    DESCRIPTION_FIELD: test_description,
                    DOCS_URL_FIELD: test_docs_url,
                    SOURCE_TABLE_FIELD: tablename,
                    **row,
                }
                for row in query_results
            ]

            if not failed_tests_by_category.get(category):
                failed_tests_by_category[category] = FailedTestGroup()
            failed_tests_by_category[category].update(failed_tests)

    return failed_tests_by_category


def get_category_from_node(node: typing.Dict) -> str:
    """Given a node representing a dbt test failure, return the category
    that the test should go in."""
    if meta_category := node.get("meta", {}).get("category"):
        return meta_category

    for dependency_macro in node["depends_on"]["macros"]:
        # Custom generic tests are always formatted like
        # macro.dbt.test_<generic_name>
        if dependency_macro.startswith("macro.athena.test_"):
            return dependency_macro.split("macro.athena.test_")[-1]

    return DEFAULT_TEST_CATEGORY


def get_tablename_from_node(node: typing.Dict) -> str:
    """Given a node representing a dbt test failure, return the name of the
    table that the test is testing."""
    if meta_tablename := node.get("meta", {}).get("table_name"):
        # If meta.table_name is set, treat it as an override
        return meta_tablename

    # Search for the model that is implicated in this test via the
    # depends_on key
    models = node.get("depends_on", {}).get("nodes", [])
    if not models:
        raise ValueError(
            "Can't infer tablename: Missing `depends_on.nodes` attribute for "
            f"test {node['name']}. You may need to add a `meta.table_name` "
            "attribute to the test config"
        )
    # Cross-table comparisons often involve multiple models; we have
    # determined experimentally that the last one is usually
    # the model that the test is concerned with, although if this
    # returns incorrect results in some cases we can override them
    # with the `meta.table_name` attribute
    model = models[-1]

    # Reference format for models/sources is:
    # <"model"/"source">.athena.<schema_name>.<table_name>
    return model.split(".")[-1]


def add_sheet_to_workbook(
    workbook: openpyxl.Workbook,
    sheet_title: str,
    failed_test_group: FailedTestGroup,
) -> None:
    """Add a sheet of failed dbt tests to an openpyxl Workbook."""
    # openpyxl Workbooks are created with one untitled active sheet by
    # default, so rename and fill out that sheet before creating any
    # new sheets
    sheet: Worksheet
    if workbook.sheetnames == ["Sheet"]:
        sheet = workbook.active
    else:
        sheet = workbook.create_sheet()

    sheet.title = sheet_title
    sheet.append(failed_test_group.fieldnames)

    # Style the header differently from rows so that it is visually
    # distinct
    font = openpyxl.styles.Font(bold=True)
    for cell in sheet[1]:
        cell.font = font
    sheet.frozen_panes = "A2"  # Freeze the header row

    for row in failed_test_group.rows:
        # Convert row values to string so that Excel doesn't apply
        # autoformatting
        output_row = [str(cell) if cell is not None else cell for cell in row]
        sheet.append(output_row)

    # Hide columns that are intended for debugging only, so that they don't
    # get in the way of non-technical workbook consumers
    for col_idx in failed_test_group.debugging_field_indexes:
        sheet.column_dimensions[col_idx].hidden = True


if __name__ == "__main__":
    main()
