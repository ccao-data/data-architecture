#!/usr/bin/env python3
#
# Generates an Excel workbook of dbt test failures that can be shared with
# other teams for review and correction, along with metadata parquet files
# that can be uploaded to S3 for long-term result tracking.
#
# This script assumes that it is being run in sequence after a call to
# `dbt test --store-failures`, since it depends on two files created by
# that operation (target/run_results.json and target/manifest.json).
# It also requires Python dependencies be installed from
# generate_dbt_test_workbook_requirements.txt.
#
# Accepts three optional positional arguments:
#
#   1. The local path to a run_results.json file generated by a test run
#     * If not present, defaults to './target/run_results.json'
#   2. The local path to a manifest.json file with the compiled dbt DAG
#     * If not present, defaults to './target/manifest.json'
#   3. The directory to which output artifacts should be written
#     * If not present, defaults to './qc_test_results_<date>/'
#
# Expects one optional environment variable to be set:
#
#  1.AWS_ATHENA_S3_STAGING_DIR: Location in S3 where Athena query results
#    should be written. If missing, defaults to the
#    ccao-athena-results-us-east-1 bucket
#
# Outputs three files:
#
#   1. `qc_test_failures_<date>.xlsx`: Excel workbook to share with other teams
#   2. `run.parquet`: Metadata about this run, for upload to S3
#   3. `run_test.parquet`: Metadata about tests (name, category, etc.)
#      in this run, for upload to S3
#   4. `run_test_result.parquet`: Metadata about test results (pass, fail,
#      number of failing rows, etc.) in this run, for upload to S3
#
# Each sheet in the output workbook represents a category of test, e.g.
# "valid_range" or "not_null"; each row in a sheet represents a row in a
# database that failed a test, with enough metadata that a reader can
# figure out what conditions caused the test to fail and investigate the
# root cause.
#
# Example usage:
#
#   AWS_ATHENA_S3_STAGING_DIR=s3://foo-bar-baz/ \
#       python3 generate_dbt_test_workbook.py \
#       ./target/run_results.json \
#       ./target/manifest.json \
#       ./qc_test_results/

import dataclasses
import datetime
import decimal
import enum
import hashlib
import os
import pathlib
import re
import sys
import typing

import openpyxl
import openpyxl.cell
import openpyxl.styles
import openpyxl.styles.colors
import openpyxl.utils
import pyarrow
import pyarrow.parquet
import pyathena
import pyathena.cursor
import simplejson as json
import yaml

# Tests without a config.meta.category property will be grouped in
# this default category
DEFAULT_TEST_CATEGORY = "miscellaneous"
# Prefix for the URL location of a test in the dbt docs
DOCS_URL_PREFIX = "https://ccao-data.github.io/data-architecture/#!/test"
# The S3 bucket where Athena query results are stored
AWS_ATHENA_S3_STAGING_DIR = os.getenv(
    "AWS_ATHENA_S3_STAGING_DIR", "s3://ccao-athena-results-us-east-1/"
)
# Field names that are used in the output workbook
SOURCE_TABLE_FIELD = "source_table"
DESCRIPTION_FIELD = "description"
TEST_NAME_FIELD = "test_name"
DOCS_URL_FIELD = "docs_url"
TAXYR_FIELD = "taxyr"
PARID_FIELD = "parid"
CARD_FIELD = "card"
TOWNSHIP_FIELD = "township_code"
WHO_FIELD = "who"
WEN_FIELD = "wen"
# Overrides for default display names for dbt tests
CUSTOM_TEST_NAMES = {
    "macro.athena.test_accepted_range": "incorrect_values",
    "macro.dbt_utils.test_accepted_range": "incorrect_values",
    "macro.athena.test_accepted_values": "incorrect_values",
    "macro.athena.test_not_accepted_values": "incorrect_values",
    "macro.dbt_utils.test_not_accepted_values": "incorrect_values",
    "macro.athena.test_unique_combination_of_columns": "duplicate_records",
    "macro.dbt_utils.test_unique_combination_of_columns": "duplicate_records",
    "macro.athena.test_not_null": "missing_values",
    "macro.athena.test_res_class_matches_pardat": "class_mismatch_or_issue",
}
# Directory to store failed test caches
TEST_CACHE_DIR = "test_cache"


class Status(enum.Enum):
    PASS = "pass"
    FAIL = "fail"

    def __repr__(self) -> str:
        return self.value.upper()


class TestResult:
    """Class to store results for an individual test."""

    def __init__(
        self,
        name: str,
        status: Status,
        description: str,
        elapsed_time: decimal.Decimal,
        failing_rows: typing.Optional[typing.List[typing.Dict]] = None,
    ) -> None:
        """
        The failing_rows list should be formatted like the rows
        returned by a csv.DictReader or a DictCursor, i.e. a list of
        dicts mapping `{column_name: row_value}`.
        """
        self.name = name
        self.status = status
        self.description = description
        self.elapsed_time = elapsed_time
        self.failing_rows: typing.List[typing.Dict] = failing_rows or []

    def __repr__(self) -> str:
        return (
            f"TestResult(name={self.name!r}, status={self.status!r}, "
            f"description={self.description!r}, "
            f"elapsed_time={self.elapsed_time!r}, "
            f"num_failing_rows={len(self.failing_rows)})"
        )

    @property
    def fieldnames(self) -> typing.List[str]:
        """Return a list of strings representing the fieldnames for any
        failing_rows of this test. Returns an empty list if the test
        passed."""
        fieldnames = []
        for row in self.failing_rows:
            for fieldname in row.keys():
                if fieldname not in fieldnames:
                    fieldnames.append(fieldname)
        return fieldnames

    def to_dict(self) -> typing.Dict:
        """Serialize the TestResult object as a dictionary."""
        return {
            "name": self.name,
            "status": self.status.value,
            "description": self.description,
            "elapsed_time": self.elapsed_time,
            "failing_rows": self.failing_rows,
        }

    @classmethod
    def from_dict(cls, result_dict: typing.Dict) -> "TestResult":
        """Deserialize a TestResult object from a dictionary."""
        return TestResult(
            name=result_dict["name"],
            status=Status(result_dict["status"]),
            description=result_dict["description"],
            elapsed_time=result_dict["elapsed_time"],
            failing_rows=result_dict["failing_rows"],
        )

    def split_by_township(self) -> typing.List["TownshipTestResult"]:
        """Split out this TestResult object into one or more TestResults
        based on the township code of each failing row. If there are no failing
        rows, or if all the failing rows"""
        # Split out the failing rows by township so that we know which
        # townships are represented in this test's failures
        failing_rows_by_township = {}
        for row in self.failing_rows:
            township_code = row[TOWNSHIP_FIELD]
            if not failing_rows_by_township.get(township_code):
                failing_rows_by_township[township_code] = []
            failing_rows_by_township[township_code].append(row)

        # These kwargs are shared by all TownshipTestResults, regardless of
        # township code or failure status
        base_kwargs = {
            "name": self.name,
            "status": self.status,
            "description": self.description,
            "elapsed_time": self.elapsed_time,
        }

        # If we have any failing rows, split out separate TownshipTestResult
        # objects for each township/row group; otherwise, just create one
        # object with a null township mapped to the passing test
        if failing_rows_by_township:
            return [
                TownshipTestResult(
                    township_code=township_code,
                    failing_rows=rows,
                    **base_kwargs,
                )
                for township_code, rows in failing_rows_by_township.items()
            ]
        return [
            TownshipTestResult(
                township_code=None, failing_rows=[], **base_kwargs
            )
        ]


class TownshipTestResult(TestResult):
    """A variant of TestResult for a test whose results all share the same
    township. Note that township_code is only present in the case of failing
    tests; since passing tests have no township (or, thinking of it
    differently, passing tests encompass all of the townships), the
    township_code will always be None in the case of a passing test."""

    def __init__(
        self, township_code: typing.Optional[str], *args, **kwargs
    ) -> None:
        self.township_code = township_code
        super().__init__(*args, **kwargs)


class TestCategory:
    """Class to store TestResult objects for a group of dbt tests that share
    the same category. Provides convenience methods for formatting those
    results for output to a workbook and saving them to a cache."""

    # Names of fields that are used for debugging
    _debugging_fieldnames = [TEST_NAME_FIELD, DOCS_URL_FIELD]
    # Names of fields that identify the test
    _test_metadata_fieldnames = [
        *[SOURCE_TABLE_FIELD, DESCRIPTION_FIELD],
        *_debugging_fieldnames,
    ]
    # Names of fields that are used for diagnostics
    _diagnostic_fieldnames = [
        TAXYR_FIELD,
        PARID_FIELD,
        CARD_FIELD,
        TOWNSHIP_FIELD,
        WHO_FIELD,
        WEN_FIELD,
    ]
    # The complete set of fixed fields
    _fixed_fieldnames = [
        *_test_metadata_fieldnames,
        *_diagnostic_fieldnames,
    ]

    def __init__(
        self,
        category: str,
        results: typing.Optional[typing.List[TestResult]] = None,
    ) -> None:
        self.category = category
        self.test_results: typing.List[TestResult] = results or []

    def to_dict(self) -> typing.Dict:
        """Serialize the TestCategory object as a dictionary."""
        return {
            "category": self.category,
            "test_results": [result.to_dict() for result in self.test_results],
        }

    def __repr__(self) -> str:
        num_failing_rows = sum(
            len(result.failing_rows) for result in self.test_results
        )
        return (
            f"TestCategory(category={self.category!r}, "
            f"status={self.status!r}, "
            f"num_tests={len(self.test_results)}, "
            f"num_failing_rows={num_failing_rows})"
        )

    @classmethod
    def from_dict(cls, category_dict: typing.Dict) -> "TestCategory":
        """Deserialize a TestCategory object from a dictionary."""
        return TestCategory(
            category=category_dict["category"],
            results=[
                TestResult.from_dict(result_dict)
                for result_dict in category_dict["test_results"]
            ],
        )

    @property
    def fieldnames(self) -> typing.List[str]:
        """Get a list of fieldnames that encapsulates all of the fieldnames
        for all of the rows of tests tracked by this group."""
        fieldnames = []
        for result in self.test_results:
            for fieldname in result.fieldnames:
                if fieldname not in fieldnames:
                    fieldnames.append(fieldname)

        # Remove any fixed fieldnames from the ordered list that are not
        # present in this group
        fixed_field_order = [
            field for field in self._fixed_fieldnames if field in fieldnames
        ]

        # Reorder the fieldnames so that diagnostic fields are presented in the
        # correct order
        for field in reversed(fixed_field_order):
            fieldnames.insert(0, fieldnames.pop(fieldnames.index(field)))

        return fieldnames

    @property
    def rows(self) -> typing.List[typing.List]:
        """Format the rows of tests tracked by this group, with
        fieldname data excluded. The combination of this property and the
        `fieldnames` property can be used to write to a csv.Writer or
        to an openpyxl.Workbook sheet for the tests tracked by this group."""
        fieldnames = self.fieldnames
        return [
            [row.get(fieldname) for fieldname in fieldnames]
            for result in self.test_results
            for row in result.failing_rows
        ]

    @property
    def status(self) -> Status:
        """Return an aggregate status for this category based on the statuses
        of its TestResult objects."""
        return (
            Status.PASS
            if all(
                result.status == Status.PASS for result in self.test_results
            )
            else Status.FAIL
        )

    def add_to_workbook(self, workbook: openpyxl.Workbook) -> None:
        """Add a sheet of failed dbt tests to an openpyxl Workbook using data
        from the TestCategory object. Note that we expect the workbook to be
        initialized with write_only=True."""
        # Only add this category to the workbook if it has any failing tests
        if self.status == Status.PASS:
            print(
                f"Skipping add_to_workbook for category {self.category} since "
                f"its status is '{Status.PASS.value}'"
            )
            return

        # openpyxl Workbooks are typically created with one untitled active
        # sheet by default, but write-only sheets are an exception to this
        # rule, so we always have to create a new sheet
        sheet = workbook.create_sheet()
        sheet.title = self.category

        # Freeze the header row. The syntax for the freeze_panes attribute is
        # undocumented, but it freezes all rows above and all columns to the
        # left of the given cell identifier. Note that freeze operations must
        # be performed before any data is added to a sheet in a write-only
        # workbook
        data_header_idx = 3  # We have 3 headers; 2 for grouping and 1 for data
        freeze_pane_letter = openpyxl.utils.get_column_letter(
            len(self.test_metadata_fieldnames) + 1
        )
        freeze_pane_number = data_header_idx + 1
        sheet.freeze_panes = f"{freeze_pane_letter}{freeze_pane_number}"

        # Hide columns that are intended for debugging only, so that they don't
        # get in the way of non-technical workbook consumers
        for col_idx in self.debugging_field_indexes:
            sheet.column_dimensions[col_idx].hidden = True

        # Create groupings for columns with a special group header
        bold_font = openpyxl.styles.Font(bold=True)
        italic_font = openpyxl.styles.Font(italic=True)
        title_row, subtitle_row, header_row, merged_cell_range = [], [], [], []
        column_groups = {
            self.test_metadata_field_indexes: {
                "title": "Test description fields",
                "subtitle": "These fields identify a failing test.",
                "fieldnames": self.test_metadata_fieldnames,
                "style": "20 % - Accent4",
                "header_style": "Accent4",
            },
            self.diagnostic_field_indexes: {
                "title": "Unique identifier fields",
                "subtitle": (
                    "These fields identify the row that is failing a test."
                ),
                "fieldnames": self.diagnostic_fieldnames,
                "style": "20 % - Accent1",
                "header_style": "Accent1",
            },
            self.nonfixed_field_indexes: {
                "title": "Problematic fields",
                "subtitle": (
                    "These fields contain values that are causing the test "
                    "to fail."
                ),
                "fieldnames": self.nonfixed_fieldnames,
                "style": "20 % - Accent2",
                "header_style": "Accent2",
            },
        }
        for col_group_indexes, col_metadata in column_groups.items():
            # Sometimes there are no problematic fields for a given test;
            # if this is the case, skip it
            if not col_group_indexes:
                continue

            # Save merged cell info
            for cell_range in [
                f"{col_group_indexes[0]}1:{col_group_indexes[-1]}1",
                f"{col_group_indexes[0]}2:{col_group_indexes[-1]}2",
            ]:
                merged_cell_range.append(cell_range)

            # Fill out and format grouping header
            title_cell = openpyxl.cell.WriteOnlyCell(
                sheet, value=col_metadata["title"]
            )
            title_cell.style = "Note"
            title_cell.font = bold_font
            title_row.append(title_cell)
            # Flesh out the empty title row cells that will be merged later on
            for _ in range(len(col_group_indexes) - 1):
                title_row.append("")

            subtitle_cell = openpyxl.cell.WriteOnlyCell(
                sheet, value=col_metadata["subtitle"]
            )
            subtitle_cell.style = "Note"
            subtitle_cell.font = italic_font
            subtitle_row.append(subtitle_cell)
            for _ in range(len(col_group_indexes) - 1):
                subtitle_row.append("")

            # Fill out and format the data header
            for fieldname in col_metadata["fieldnames"]:
                header_cell = openpyxl.cell.WriteOnlyCell(
                    sheet, value=fieldname
                )
                header_cell.style = col_metadata["header_style"]
                header_cell.font = openpyxl.styles.Font(
                    bold=True, color=openpyxl.styles.colors.WHITE
                )
                header_row.append(header_cell)

        # Initialize the column widths based on the length of values in
        # the header row
        column_widths = {
            openpyxl.utils.get_column_letter(idx + 1): len(fieldname) + 2
            for idx, fieldname in enumerate(self.fieldnames)
        }
        # Iterate the rows to extract data and optionally update the column
        # widths if the length of the cell value exceeds the length of the
        # header value
        data_rows = []
        for row in self.rows:
            data_row = []
            # Start enumeration at 1 since openpyxl columns are 1-indexed
            for col_idx, cell in enumerate(row, 1):
                # Convert row values to string so that Excel doesn't apply
                # autoformatting
                cell_str = str(cell) if cell is not None else ""
                cell = openpyxl.cell.WriteOnlyCell(sheet, value=cell_str)

                # Retrieve the cell style from the column groupings if one
                # exists
                cell_style = None
                column_letter = openpyxl.utils.get_column_letter(col_idx)
                for col_group_indexes, col_metadata in column_groups.items():
                    if column_letter in col_group_indexes:
                        cell_style = col_metadata["style"]
                if cell_style:
                    cell.style = cell_style
                data_row.append(cell)

                # Check if this cell is longer than the longest cell we've seen
                # so far, and adjust the column dimensions accordingly
                column_letter = openpyxl.utils.get_column_letter(col_idx)
                column_widths[column_letter] = max(
                    column_widths.get(column_letter, 0), len(cell_str)
                )

            data_rows.append(data_row)

        # Update column widths so that they fit the longest column
        for (
            column_letter,
            column_width,
        ) in column_widths.items():
            # Pad with an extra two characters to account for the fact that
            # non-monospace fonts do not have consistent character widths,
            # and set a hard limit of 75 characters so no one field takes over
            # the viewport of the spreadsheet
            width = min(column_width + 2, 75)
            sheet.column_dimensions[column_letter].width = width

        # Add filters to fixed columns (i.e. columns that appear in every sheet
        # in the same position)
        fixed_field_indexes = self.fixed_field_indexes
        sheet_max_row_idx = data_header_idx + len(data_rows)
        min_fixed_idx = f"{fixed_field_indexes[0]}{data_header_idx}"
        max_fixed_idx = f"{fixed_field_indexes[-1]}{sheet_max_row_idx}"
        fixed_field_range = f"{min_fixed_idx}:{max_fixed_idx}"
        sheet.auto_filter.ref = fixed_field_range

        # Add the data to the sheet. This should be one of the last steps in
        # this function, since write-only sheets require all formatting to be
        # set before data is added
        sheet.append(title_row)
        sheet.append(subtitle_row)
        sheet.append(header_row)
        for data_row in data_rows:
            sheet.append(data_row)

        # Merge cells in the grouping headers. This approach is a bit of a hack
        # since merged cells are not fully supported in write-only workbooks,
        # hence why it takes place _after_ rows have been added to the sheet
        # whereas most formatting options for write-only workbooks need to
        # happen _before_ data is added. See here for details:
        # https://stackoverflow.com/a/66159254
        for cell_range in merged_cell_range:
            sheet.merged_cells.ranges.add(cell_range)

    @property
    def debugging_fieldnames(self) -> typing.List[str]:
        """Get a list of fieldnames (e.g. ["foo", "bar"]) for fields that
        are used for debugging."""
        return self._filter_for_existing_fieldnames(self._debugging_fieldnames)

    @property
    def debugging_field_indexes(self) -> tuple:
        """Get a tuple of field indexes (e.g. ["A", "B"]) for fields that
        are used for debugging."""
        return self._filter_for_existing_field_indexes(
            self._debugging_fieldnames
        )

    @property
    def test_metadata_fieldnames(self) -> typing.List[str]:
        """Get a list of fieldnames (e.g. ["foo", "bar"]) for fields that
        are used for identifying tests."""
        return self._filter_for_existing_fieldnames(
            self._test_metadata_fieldnames
        )

    @property
    def test_metadata_field_indexes(self) -> tuple:
        """Get a tuple of field indexes (e.g. ["A", "B"]) for fields that
        are used for identifying tests."""
        return self._filter_for_existing_field_indexes(
            self._test_metadata_fieldnames
        )

    @property
    def diagnostic_fieldnames(self) -> typing.List[str]:
        """Get a list of fieldnames (e.g. ["foo", "bar"]) for fields that
        are used for diagnostics."""
        return self._filter_for_existing_fieldnames(
            self._diagnostic_fieldnames
        )

    @property
    def diagnostic_field_indexes(self) -> tuple:
        """Get a tuple of field indexes (e.g. ["A", "B"]) for fields that
        are used for diagnostics."""
        return self._filter_for_existing_field_indexes(
            self._diagnostic_fieldnames
        )

    @property
    def fixed_fieldnames(self) -> typing.List[str]:
        """Get a list of fieldnames (e.g. ["foo", "bar"]) for fields that
        are fixed (i.e. whose position is always at the start of the sheet,
        for diagnostic purposes)."""
        return self._filter_for_existing_fieldnames(self._fixed_fieldnames)

    @property
    def fixed_field_indexes(self) -> tuple:
        """Get a list of field indexes (e.g. ["A", "B"]) for fields that
        are fixed (i.e. whose position is always at the start of the sheet,
        for diagnostic purposes)."""
        return self._filter_for_existing_field_indexes(self._fixed_fieldnames)

    @property
    def nonfixed_fieldnames(self) -> typing.List[str]:
        """Get a list of field names (e.g. ["foo", "bar"]) for fields that
        are nonfixed (i.e. whose position comes after the fixed fields in the
        sheet and are thus variable)."""
        fieldnames = self.fieldnames
        fixed_fieldnames = self._fixed_fieldnames
        return [field for field in fieldnames if field not in fixed_fieldnames]

    @property
    def nonfixed_field_indexes(self) -> tuple:
        """Get a list of field indexes (e.g. ["A", "B"]) for fields that
        are nonfixed (i.e. whose position comes after the fixed fields in the
        sheet and are thus variable)."""
        nonfixed_fieldnames = self.nonfixed_fieldnames
        return self._filter_for_existing_field_indexes(nonfixed_fieldnames)

    def _filter_for_existing_fieldnames(
        self, possible_fieldnames: typing.List[str]
    ) -> typing.List[str]:
        """Helper function to filter a list of `possible_fieldnames` for
        only those fields that exist in the test group, returning the
        names of the fields (e.g. ["foo", "bar"])."""
        existing_fieldnames = self.fieldnames
        return [
            field
            for field in possible_fieldnames
            if field in existing_fieldnames
        ]

    def _filter_for_existing_field_indexes(
        self, possible_fieldnames: typing.List[str]
    ) -> tuple:
        """Helper function to filter a list of `possible_fieldnames` for
        only those fields that exist in the test group, returning the
        indexes of the fields (e.g. ["A", "B"])."""
        existing_fieldnames = self.fieldnames
        return tuple(
            openpyxl.utils.get_column_letter(
                # openpyxl is 1-indexed while the index() method is 0-indexed
                existing_fieldnames.index(field)
                + 1
            )
            for field in self._filter_for_existing_fieldnames(
                possible_fieldnames
            )
        )


def main() -> None:
    """Entrypoint to this script. Parses dbt test results and writes artifacts
    to the output directory with metadata about tests."""
    try:
        run_results_filepath = sys.argv[1]
    except IndexError:
        run_results_filepath = os.path.join("target", "run_results.json")

    try:
        manifest_filepath = sys.argv[2]
    except IndexError:
        manifest_filepath = os.path.join("target", "manifest.json")

    date_today = datetime.datetime.today().strftime("%Y-%m-%d")
    try:
        output_directory = sys.argv[3]
    except IndexError:
        output_directory = f"qc_test_results_{date_today}"

    test_cache_path = get_test_cache_path(
        run_results_filepath,
        manifest_filepath,
    )

    if os.path.isfile(test_cache_path):
        print(f"Loading test results from cache at {test_cache_path}")
        test_categories = get_test_categories_from_file(test_cache_path)
    else:
        print(
            f"Test cache not found at {test_cache_path}, loading test results "
            "from Athena"
        )
        test_categories = get_test_categories_from_athena(
            run_results_filepath,
            manifest_filepath,
        )
        print(f"Saving test results to the cache at {test_cache_path}")
        save_test_categories_to_file(test_categories, test_cache_path)

    print("Generating the output workbook")
    # It's important to use a write-only workbook here because otherwise
    # the metadata required to store cell info about a large number of failing
    # tests can cause the process to run out of memory
    workbook = openpyxl.Workbook(write_only=True)
    for test_category in test_categories:
        print(f"Adding sheet for {test_category.category}")
        test_category.add_to_workbook(workbook)

    pathlib.Path(output_directory).mkdir(exist_ok=True)
    workbook_filepath = os.path.join(
        output_directory, f"qc_test_failures_{date_today}.xlsx"
    )
    workbook.save(workbook_filepath)
    print(f"Output workbook saved to {workbook_filepath}")

    # Generate and save metadata tables as parquet
    test_run_metadata = TestRunMetadata.create(run_results_filepath)
    test_run_result_metadata_list = TestRunResultMetadata.create_list(
        test_categories, run_results_filepath
    )
    for metadata_list, tablename, partition_cols in [
        ([test_run_metadata], "test_run", ["run_id"]),
        (test_run_result_metadata_list, "test_run_result", ["run_id"]),
    ]:
        table = pyarrow.Table.from_pylist(
            [dataclasses.asdict(meta_obj) for meta_obj in metadata_list]
        )
        metadata_root_path = os.path.join(output_directory, tablename)
        pyarrow.parquet.write_to_dataset(
            table, metadata_root_path, partition_cols
        )
        print(f"{tablename} metadata saved to {metadata_root_path}/")


@dataclasses.dataclass
class TestRunMetadata:
    """Metadata object storing information about a test run."""

    run_id: str
    run_date: str
    elapsed_time: decimal.Decimal
    var_year_start: str
    var_year_end: str

    @classmethod
    def create(cls, run_results_filepath: str) -> "TestRunMetadata":
        """Generate a TestRunMetadata object from a filepath to a
        run_results.json file."""
        with open(run_results_filepath) as run_results_fobj:
            run_results = json.load(run_results_fobj)

        run_id = run_results["metadata"]["invocation_id"]
        run_dt_str = run_results["metadata"]["generated_at"]
        run_dt = datetime.datetime.strptime(
            run_dt_str, "%Y-%m-%dT%H:%M:%S.%fZ"
        )
        run_date = run_dt.strftime("%Y-%m-%d")
        elapsed_time = run_results["elapsed_time"]

        # Extract dbt vars
        run_vars = run_results["args"]["vars"]
        var_year_start = run_vars.get("test_qc_year_start")
        var_year_end = run_vars.get("test_qc_year_start")

        # If dbt vars weren't set on the command line, the defaults won't exist
        # in run_results.json, so we have to parse them from the dbt project
        # config
        if not var_year_start or not var_year_end:
            with open("dbt_project.yml") as project_fobj:
                project = yaml.safe_load(project_fobj)
            var_year_start = (
                var_year_start or project["vars"]["test_qc_year_start"]
            )
            var_year_end = var_year_end or project["vars"]["test_qc_year_end"]

        return cls(
            run_id=run_id,
            run_date=run_date,
            elapsed_time=elapsed_time,
            var_year_start=var_year_start,
            var_year_end=var_year_end,
        )


@dataclasses.dataclass
class TestRunResultMetadata:
    """Metadata object storing information about test results in a run."""

    run_id: str
    test_name: str
    category: str
    description: str
    township_code: typing.Optional[str]
    status: str  # Serialize Status enum to str for output to parquet
    elapsed_time: decimal.Decimal
    num_failing_rows: int

    @classmethod
    def create_list(
        cls,
        test_categories: typing.List[TestCategory],
        run_results_filepath: str,
    ) -> typing.List["TestRunResultMetadata"]:
        """Generate a list of TestRunMetadata object from a list of
        TestCategory objects representing the categories in the run and a
        filepath to a run_results.json file."""
        with open(run_results_filepath) as run_results_fobj:
            run_results = json.load(run_results_fobj)

        run_id = run_results["metadata"]["invocation_id"]

        return [
            TestRunResultMetadata(
                run_id=run_id,
                test_name=township_result.name,
                category=test_category.category,
                description=township_result.description,
                township_code=township_result.township_code,
                status=township_result.status.value,
                elapsed_time=township_result.elapsed_time,
                num_failing_rows=len(township_result.failing_rows),
            )
            for test_category in test_categories
            for test_result in test_category.test_results
            for township_result in test_result.split_by_township()
        ]


def get_test_cache_path(
    run_results_filepath: str, manifest_filepath: str
) -> str:
    """Return the path to the cache where test results are stored.
    The `run_results_filepath` and `manifest_filepath` are used to generated
    a hash key that uniquely defines the cache key for a given test run."""
    with open(run_results_filepath, "rb") as run_results_file:
        run_results_hash = hashlib.md5(run_results_file.read()).hexdigest()

    with open(manifest_filepath, "rb") as manifest_file:
        manifest_hash = hashlib.md5(manifest_file.read()).hexdigest()

    return os.path.join(
        TEST_CACHE_DIR,
        f"run_{run_results_hash}_manifest_{manifest_hash}.json",
    )


def get_test_categories_from_file(
    file_path: str,
) -> typing.List[TestCategory]:
    """Load a list of TestCategory objects from a cache located at
    `file_path`."""
    with open(file_path) as cache_file:
        test_category_dicts = json.load(cache_file, use_decimal=True)
    return [
        TestCategory.from_dict(category_dict)
        for category_dict in test_category_dicts
    ]


def save_test_categories_to_file(
    test_categories: typing.List[TestCategory], file_path: str
) -> None:
    """Save a list of TestCategory objects to a cache located at
    `file_path`."""
    test_category_dicts = [
        test_category.to_dict() for test_category in test_categories
    ]
    os.makedirs(TEST_CACHE_DIR, exist_ok=True)
    with open(file_path, "w") as cache_file:
        json.dump(test_category_dicts, cache_file, use_decimal=True)


def get_test_categories_from_athena(
    run_results_filepath: str, manifest_filepath: str
) -> typing.List[TestCategory]:
    """Load a list of TestCategory objects by querying Athena for
    test results generated from a `dbt test --store-failures` call."""
    with open(run_results_filepath) as run_results_fobj:
        run_results = json.load(run_results_fobj)

    with open(manifest_filepath) as manifest_fobj:
        manifest = json.load(manifest_fobj)

    test_categories = get_test_categories(run_results, manifest)
    if not test_categories:
        raise ValueError(f"{run_results_filepath} contains no test results")

    return test_categories


def get_test_categories(
    run_results: typing.Dict, manifest: typing.Dict
) -> typing.List[TestCategory]:
    """Given two artifacts from a `dbt test --store-failures` call (a
    run_results.json file dict and a manifest.json file dict), generates a list
    of TestCategory objects storing the results of the tests."""
    conn = pyathena.connect(
        s3_staging_dir=AWS_ATHENA_S3_STAGING_DIR,
        region_name="us-east-1",
        cursor_class=pyathena.cursor.DictCursor,
    )
    cursor = conn.cursor()

    tests_by_category: typing.Dict[str, TestCategory] = {}

    for run_result in run_results["results"]:
        unique_id = run_result["unique_id"]
        node = manifest["nodes"].get(unique_id)
        if node is None:
            raise ValueError(f"Missing dbt manifest node with id {unique_id}")

        test_name = node["name"]
        status = run_result["status"]
        execution_time = run_result["execution_time"]

        meta = node.get("meta", {})
        category = get_category_from_node(node)
        tablename = get_tablename_from_node(node)
        test_description = meta.get("description")

        if status == Status.PASS.value:
            test_result = TestResult(
                name=test_name,
                status=Status.PASS,
                description=test_description,
                elapsed_time=execution_time,
                failing_rows=[],
            )

            if not tests_by_category.get(category):
                tests_by_category[category] = TestCategory(category=category)
            tests_by_category[category].test_results.append(test_result)

        elif status == Status.FAIL.value:
            # Link to the test's page in the dbt docs, for debugging
            test_docs_url = f"{DOCS_URL_PREFIX}/{unique_id}"

            # Get the fully-qualified name of the table that stores failures
            # for this test so that we can query it
            test_results_relation_name = node.get("relation_name")
            if test_results_relation_name is None:
                raise ValueError(
                    f"Missing relation_name attribute for test {test_name}. "
                    "Did you run `dbt test` with the --store-failures flag?"
                )

            print(f"Querying failed rows from {test_results_relation_name}")
            # Athena SHOW COLUMNS doesn't allow double quoted tablenames
            relation_name_unquoted = test_results_relation_name.replace(
                '"', "`"
            )
            cursor.execute(f"show columns in {relation_name_unquoted}")
            # SHOW COLUMNS often returns field names with trailing whitespace
            fieldnames = [row["field"].strip() for row in cursor]

            test_results_query = f"select * from {test_results_relation_name}"
            if (
                PARID_FIELD in fieldnames
                and TAXYR_FIELD in fieldnames
                and TOWNSHIP_FIELD not in fieldnames
            ):
                # If parid and taxyr are present, try to retrieve the township
                # code for every row. It's most efficient to do this via a
                # join in the query rather than in a Python lookup since
                # legdat has 43m rows
                test_results_query = f"""
                    select test_results.*, leg.user1 as {TOWNSHIP_FIELD}
                    from {test_results_relation_name} as test_results
                    left join iasworld.legdat as leg
                        on leg.{PARID_FIELD} = test_results.{PARID_FIELD}
                        and leg.{TAXYR_FIELD} = test_results.{TAXYR_FIELD}
                """

            cursor.execute(test_results_query)
            query_results = cursor.fetchall()
            if len(query_results) == 0:
                raise ValueError(
                    f"Test {test_name} has status 'fail' but no failing rows "
                    "in Athena"
                )

            # Add custom fields to query results that we don't expect to be
            # included in the response
            failing_rows = [
                {
                    TEST_NAME_FIELD: test_name,
                    DESCRIPTION_FIELD: test_description,
                    DOCS_URL_FIELD: test_docs_url,
                    SOURCE_TABLE_FIELD: tablename,
                    **row,
                }
                for row in query_results
            ]
            test_result = TestResult(
                name=test_name,
                status=Status.FAIL,
                description=test_description,
                elapsed_time=execution_time,
                failing_rows=failing_rows,
            )

            if not tests_by_category.get(category):
                tests_by_category[category] = TestCategory(category=category)
            tests_by_category[category].test_results.append(test_result)

        else:
            raise ValueError(
                f"Got unrecognized status '{status}' for node {unique_id} "
                "in dbt run results"
            )

    # Now that we've accumulated all of the test results and they are grouped
    # into categories, we no longer need the category key in the dict, so
    # transform the output into a list
    return list(tests_by_category.values())


def get_category_from_node(node: typing.Dict) -> str:
    """Given a Node for a test extracted from a dbt manifest, return the
    category that the test should go in."""
    if meta_category := node.get("meta", {}).get("category"):
        return meta_category

    for dependency_macro in node["depends_on"]["macros"]:
        if custom_test_name := CUSTOM_TEST_NAMES.get(dependency_macro):
            return custom_test_name
        # Custom generic tests are always formatted like
        # macro.dbt.test_<generic_name>
        if dependency_macro.startswith("macro.athena.test_"):
            return dependency_macro.split("macro.athena.test_")[-1]
        # dbt_utils generic tests are always formatted like
        # macro.dbt_utils.test_<generic_name>
        if dependency_macro.startswith("macro.dbt_utils.test_"):
            return dependency_macro.split("macro.dbt_utils.test_")[-1]

    return DEFAULT_TEST_CATEGORY


def get_tablename_from_node(node: typing.Dict) -> str:
    """Given a Node for a test extracted from a dbt manifest, return the name
    of the table that the test is testing."""
    if meta_tablename := node.get("meta", {}).get("table_name"):
        # If meta.table_name is set, treat it as an override
        return meta_tablename

    # Search for the model that is implicated in this test via the
    # test_metadata.kwargs.model attribute. Note that it is common to use the
    # elements in the depends_on array for this purpose, but this approach
    # is fraught, since the order of parents for tests with multiple
    # dependencies is not clear and can differ:
    # https://github.com/dbt-labs/dbt-core/issues/6746#issuecomment-1829860236
    test_metadata = node.get("test_metadata", {})
    model_getter_str = test_metadata.get("kwargs", {}).get("model")
    if not model_getter_str:
        raise ValueError(
            "Can't infer tablename: Missing `test_metadata.kwargs.model`"
            f"attribute for test {node['name']}. You may need to add a "
            "`meta.table_name` attribute to the test config to manually "
            "specify the tablename"
        )

    # The test_metadata.kwargs.model attribute is formatted as a Jinja template
    # call to the get_where_subquery macro, so we need to extract the ref or
    # source tablename from that call
    ref_match = re.search(r"ref\('(.+)'\)", model_getter_str)
    if ref_match is not None:
        fq_model_name = ref_match.group(1)
        return fq_model_name.split(".")[-1]

    source_match = re.search(r"source\('iasworld', '(.+)'\)", model_getter_str)
    if source_match is not None:
        return source_match.group(1)

    raise ValueError(
        "Can't infer tablename: Failed to parse model name from "
        f'`test_metadata.kwargs.model` attribute "{model_getter_str}" '
        f" for test \"{node['name']}\". Inspect the dbt manifest file "
        "for more information"
    )


if __name__ == "__main__":
    main()
